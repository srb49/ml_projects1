{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "x = pd.DataFrame(data=iris.data, columns=iris.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(data=iris.target, columns=['target'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.values.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0  9]]\n",
      "Accuracy score: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = metrics.confusion_matrix(y_test, y_pred) \n",
    "print(cm)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred) \n",
    "print(\"Accuracy score:\",accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain the error?\n",
    "***Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].***\n",
    "\n",
    "The error you received is occurring because you have set the average parameter to 'binary' in your function call to precision_score(), but your target variable has more than two classes.\n",
    "\n",
    "In the context of evaluating classification models using metrics like precision, recall, and F1-score, the average parameter allows you to specify how to aggregate the scores across multiple classes.The average parameter specifies the type of averaging to be performed if the target variable has multiple classes. \n",
    "\n",
    "If you set average='binary', the function expects a binary classification problem where the target variable has only two classes. In such a case, precision is calculated for each class separately, and then the average precision across the two classes is returned.\n",
    "\n",
    "However, if the target variable has more than two classes, you need to use a different averaging method. You can set average to one of 'micro', 'macro', or 'weighted' instead. Here's what each of these options does:\n",
    "\n",
    "average='micro': Calculate precision globally by counting the total true positives, false positives, and false negatives across all classes, and then computing precision as TP / (TP + FP).\n",
    "\n",
    "average='macro': Calculate precision separately for each class and return the unweighted mean of the precisions.\n",
    "\n",
    "average='weighted': Calculate precision separately for each class and return the weighted mean of the precisions, weighted by the number of samples in each class.\n",
    "\n",
    "When average=None (the default), the function returns the precision, recall, or F1-score for each class separately, as an array. This is useful when you want to evaluate the performance of the model on each individual class.\n",
    "\n",
    "For example, if you have a multiclass classification problem with 3 classes (A, B, C), and you set average=None in a call to precision_score(), the function will return an array of 3 precision scores, one for each class. This allows you to see how well the model performs on each class separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.9736842105263158\n",
      "Recall score: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "precision = metrics.precision_score(y_test, y_pred,average='micro') \n",
    "print(\"Precision score:\",precision)\n",
    "recall = metrics.recall_score(y_test, y_pred, average='micro') \n",
    "print(\"Recall score:\",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.9666666666666667\n",
      "Recall score: 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "precision = metrics.precision_score(y_test, y_pred,average='macro') \n",
    "print(\"Precision score:\",precision)\n",
    "recall = metrics.recall_score(y_test, y_pred, average='macro') \n",
    "print(\"Recall score:\",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.9763157894736842\n",
      "Recall score: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "precision = metrics.precision_score(y_test, y_pred,average='weighted') \n",
    "print(\"Precision score:\",precision)\n",
    "recall = metrics.recall_score(y_test, y_pred, average='weighted') \n",
    "print(\"Recall score:\",recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: [1.  1.  0.9]\n",
      "Recall score: [1.     0.9375 1.    ]\n"
     ]
    }
   ],
   "source": [
    "precision = metrics.precision_score(y_test, y_pred,average=None) \n",
    "print(\"Precision score:\",precision)\n",
    "recall = metrics.recall_score(y_test, y_pred, average=None) \n",
    "print(\"Recall score:\",recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
